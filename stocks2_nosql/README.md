stocks2_nosql
=================

我们利用这一块来具体地说说如何使用Scrapy构建自己的爬虫. 网络上有很多教程,我希望可以尽可能清楚地向大家说一下创建crawler时需要留意的几个方面——这也是构建crawler的步骤.

#### 基础知识    
我们知道，网页上的文本甚至图片都是在特定的"标签"下的。例如标题会是 `<h1> title <\h1>` 标签确定了，就相当于成功地定位到了你想要的东西。

另外，网页是静态的情况下，内容几乎手到擒来(如果我们知道标签信息的话).但动态网页，比如知乎、微博上的某些需要我们"点击"后才在"当前界面"打开的那些,原来的方法便不适用了。即便我们可以看到标签信息，但Scrapy做页面解析的时候并不会"打开"它们。这就相当于那些信息被折叠了，需要进一步的操作才能拿到我们想要的数据。    
页面解析,简单地说就是,Scrapy帮我们把整个网页的结构都取下来了.这个结构包括标签内含有的信息(文本),也包括html标签的结构(层次,就像文件夹的层次一样例如 `/User/documents/Desktop` )

#### Let's Do It !    
现在，Step by Step地跟大家说说我是如何为创建爬虫做准备，到最后完善它的。    
##### 页面解析与内容定位    
在这里，我们需要两个工具：    
`.` 1. [Firebug](http://www.getfirebug.com) 这是一个Firefox的插件，下载好[Firefox](http://www.firefox.com.cn) 后安装即可。它的好处是可以可视化地选择你想要的内容，并返回它的标签信息。    
`.` 2. Scrapy Shell  可以具体地将Firebug"定位"出的标签信息解析出来。这样一来，我们既可以找到位置，又可以确认信息的内容完整性。    

##### Firebug的使用
